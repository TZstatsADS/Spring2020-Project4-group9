---
title: "Project4"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

In this project, you are going to explore matrix factorization methods for recommender system. The goal is to match consumers with most appropriate products. Matrix factorization methods characterize both items and users by vectors of factors inferred from item rating patterns. High correspondence between item and user factors leads to a recommendation. Matrix factorization generally has 3 parts:

- factorization algorithm

- regularization

- postpocessing

It is highly recommended to read this [review paper](./paper/P1 Recommender-Systems.pdf).

### Step 1 Load Data and Train-test Split
```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(0)
test_idx <- sample(1:nrow(data), round(nrow(data)/5, 0))
train_idx <- setdiff(1:nrow(data), test_idx)
data_train <- data[train_idx,]
data_test <- data[test_idx,]
```

###Step 2 Matrix Factorization
#### Step 2.1 Algorithm and Regularization
Here I perform stochastic gradien descent to do matrix factorization.
Your algorithm should consider case that there are new users and movies adding to the dataset you used to train. In other words, the dimension your matrix R, q, p is dynamic.

- For algorithms, the referenced paper are:

A1. [Stochastic Gradient Descent](./paper/P1 Recommender-Systems.pdf) Section: Learning Algorithms-Stochastic Gradient Descent

A2. [Gradient Descent with Probabilistic Assumptions](./paper/P3 probabilistic-matrix-factorization.pdf) Section 2

A3. [Alternating Least Squares](./paper/P4 Large-scale Parallel Collaborative Filtering for the Netflix Prize.pdf) Section 3.1

- For regularizations, the referenced paper are:

R1. [Penalty of Magnitudes](./paper/P1 Recommender-Systems.pdf) Section: a Basic Matrix Factorization Model

R2. [Bias and Intercepts](./paper/P1 Recommender-Systems.pdf) Section: Adding Biases

R3. [Temporal Dynamics](./paper/P5 Collaborative Filtering with Temporal Dynamics.pdf) Section 4


```{r}
U <- length(unique(data$userId))
I <- length(unique(data$movieId))
source("../lib/Matrix_Factorization.R")
```


#### Step 2.2 Parameter Tuning
Here you should tune parameters, such as the dimension of factor and the penalty parameter $\lambda$ by cross-validation.
```{r}
source("../lib/cross_validation.R")
f_list <- seq(10, 20, 10)
l_list <- seq(-2, -1, 1)
f_l <- expand.grid(f_list, l_list)
```

```{r, eval=FALSE}
result_summary <- array(NA, dim = c(nrow(f_l), 10, 4)) 
run_time <- system.time(for(i in 1:nrow(f_l)){
    par <- paste("f = ", f_l[i,1], ", lambda = ", 10^f_l[i,2])
    cat(par, "\n")
    current_result <- cv.function(data, K = 5, f = f_l[i,1], lambda = 10^f_l[i,2])
    result_summary[,,i] <- matrix(unlist(current_result), ncol = 10, byrow = T) 
    print(result_summary)
  
})

save(result_summary, file = "../output/rmse.Rdata")
```

```{r}
load("../output/rmse.Rdata")
rmse <- data.frame(rbind(t(result_summary[1,,]), t(result_summary[2,,])), train_test = rep(c("Train", "Test"), each = 4), par = rep(paste("f = ", f_l[,1], ", lambda = ", 10^f_l[,2]), times = 2)) %>% gather("epoch", "RMSE", -train_test, -par)
rmse$epoch <- as.numeric(gsub("X", "", rmse$epoch))
rmse %>% ggplot(aes(x = epoch, y = RMSE, col = train_test)) + geom_point() + facet_grid(~par)
```

#### Step 2.3 Evaluation on the Model without Postprocessing
```{r, eval= FALSE}
result <- gradesc(f = 10, lambda = 0.1,lrate = 0.01, max.iter = 100, stopping.deriv = 0.01,
                   data = data, train = data_train, test = data_test)

save(result, file = "../output/mat_fac.RData")
```

You should visualize training and testing RMSE by different epochs ([One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE](https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9)). 

```{r}
load(file = "../output/mat_fac_als.RData")
library(ggplot2)

RMSE <- data.frame(epochs = seq(10, 100, 10), Training_MSE = result$train_RMSE, Test_MSE = result$test_RMSE) %>% gather(key = train_or_test, value = RMSE, -epochs)

RMSE %>% ggplot(aes(x = epochs, y = RMSE,col = train_or_test)) + geom_point() + scale_x_discrete(limits = seq(10, 100, 10)) + xlim(c(0, 100))

```

### Step 3 Postprocessing
After matrix factorization, postprocessing will be performed to improve accuracy.

The postprocessing method used here is SVD with KNN. The referenced papers are:

P2:[Postprocessing SVD with KNN](./paper/P2 Improving regularized singular value decomposition for collaborative filtering .pdf) Section 3.5


Firstly, obtain the similarity data matrix and store it in RData file for further usage.
```{r}

m.s <- matrix(0,nrow = ncol(result$q), ncol = ncol(result$q))
for (i in 1:ncol(result$q)) {
  for (j in 1:ncol(result$q)) {
    m.s[i,j] = t(result$q[,i])%*%result$q[,j]/sqrt(sum(result$q[,i]^2))/sqrt(sum(result$q[,j]^2))
  }
}
colnames(m.s) <- colnames(result$q)
rownames(m.s) <- colnames(result$q)

save(m.s, file = "../output/movie_similarity.RData")
```


Define the KNN_pred_rating function that would be used to derive the predicted rating for a given movie ID and user ID by using KNN method and the movie factor matrix obtained above.

Use partial cross validation method to obtain an optimal k that would minimize the RMSE of the predicted rating by using the training set.
```{r}

load("../output/movie_similarity.RData")

pred_rating <- t(result$q) %*% result$p

#define a function to extract the corresponding predicted rating by using KNN for the test set.
KNN_pred_rating <- function(test_set, pred,K){
  u <- test_set[1]
  m <- test_set[2]
  
  m_idx_urated <- unique(data$movieId[which(data$userId == u)])
  
  
  mid_ch <- c()
  for (i in 1:K) {
    m_idx <- ifelse(m %in% m_idx_urated,
                    colnames(m.s)[which(m.s[as.character(m),] == sort(m.s[as.character(m),as.character(m_idx_urated)],decreasing = TRUE)[i+1])],
                    colnames(m.s)[which(m.s[as.character(m),] == sort(m.s[as.character(m),as.character(m_idx_urated)],decreasing = TRUE)[i])])
    mid_ch <- c(mid_ch,m_idx)
  }
  
  pred_rating.um <- pred[mid_ch, as.character(u)]
  
  pred_rating <- mean(pred_rating.um)
  return(pred_rating)
}


rmse_tr_te_k <- c()

k <- c(1,2,3,5,10,15)
k_cv <- 5
for (i in 1:length(k)) {
  rmse_tr_te_j <- c()
  for (j in 1:k_cv) {
    tr.te.idx <- sample(1:nrow(data_train),0.2*nrow(data_train),replace = TRUE)
    dt.tr.te <- data_train[tr.te.idx,]
    pred_tr_te_rating_k <- apply(dt.tr.te, 1, KNN_pred_rating, pred_rating,k[i])
    rmse_tr_te_j[j] <- sqrt(mean((dt.tr.te$rating - pred_tr_te_rating_k)^2))
  }
  rmse_tr_te_k[i] <- mean(rmse_tr_te_j)
  cat("The RMSE of the model for training cv using KNN postprocessing method while k = ",
      k[i]," is", rmse_tr_te_k[i],"\n")
}
rmse_tr_te_k
```

It turns out that k=5 would minimize the RMSE in predicting the movie ratings while using training set.

Try applying the KNN_pred_rating function on the test set.

```{r}

rmse_k <- c()

k <- c(1,2,3,5,10,15)
for (i in 1:length(k)) {
  pred_test_rating_k <- apply(data_test, 1, KNN_pred_rating, pred_rating,k[i])
  rmse_k[i] <- sqrt(mean((data_test$rating - pred_test_rating_k)^2))
  cat("The RMSE of the model using KNN postprocessing method while k = ",
      k[i]," is", rmse_k[i],"\n")
}
rmse_k
```

The result above shows that k=5 also minimizes the predicted movie rating on test set. Therefore we would choose k=5 as final parameter for KNN postprocessing method.


```{r}
RMSE.df <- data.frame(k = rep(c(1,2,3,5,10,15),2),
                      RMSE = c(rmse_tr_te_k,rmse_k),
                      Train_or_Test = c(rep("Training_RMSE",6),rep("Test_RMSE",6)))

ggplot(RMSE.df) +
  geom_point(aes(k, RMSE,color = Train_or_Test))


```

```{r}
tm <- system.time(pred_test_rating <- apply(data_test, 1, KNN_pred_rating, pred_rating,5))


data_test$pred <- pred_test_rating

boxplot(data_test$pred ~ data_test$rating)
#calculate RMSE
rmse <- sqrt(mean((data_test$rating - data_test$pred)^2))
cat("The RMSE of the adjusted model is", rmse,"\n")
cat("The system prediction time is", tm[1])
```


Depending on your postprocessing method, you might want to cross-validate on some parameters related to the postprocessing. Don't forget to visualize the cross-validation process through graphs.
